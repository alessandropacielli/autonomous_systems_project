{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alessandropacielli/autonomous_systems_project/blob/master/Pytorch_DQN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eL-UO54fZx3X"
   },
   "source": [
    "Install dependencies for virtual display to render the environment\n",
    "\n",
    "See [this medium post.](https://towardsdatascience.com/rendering-openai-gym-envs-on-binder-and-google-colab-536f99391cc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymmGP3TuZ3B9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: apt-get: command not found\n",
      "Collecting pyvirtualdisplay==0.2.*\n",
      "  Downloading PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
      "Collecting PyOpenGL==3.1.*\n",
      "  Downloading PyOpenGL-3.1.5-py3-none-any.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyOpenGL-accelerate==3.1.*\n",
      "  Downloading PyOpenGL-accelerate-3.1.5.tar.gz (538 kB)\n",
      "\u001b[K     |████████████████████████████████| 538 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting EasyProcess\n",
      "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
      "Using legacy 'setup.py install' for PyOpenGL-accelerate, since package 'wheel' is not installed.\n",
      "Installing collected packages: EasyProcess, pyvirtualdisplay, PyOpenGL, PyOpenGL-accelerate\n",
      "    Running setup.py install for PyOpenGL-accelerate ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed EasyProcess-0.3 PyOpenGL-3.1.5 PyOpenGL-accelerate-3.1.5 pyvirtualdisplay-0.2.5\n"
     ]
    },
    {
     "ename": "EasyProcessError",
     "evalue": "start error <EasyProcess cmd_param=['Xvfb', '-help'] cmd=['Xvfb', '-help'] oserror=[Errno 2] No such file or directory: 'Xvfb': 'Xvfb' return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/projects/uni/autonomous/autonomous_systems_project/.venv/lib64/python3.7/site-packages/easyprocess/__init__.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             self.popen = subprocess.Popen(\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             )\n",
      "\u001b[0;32m/usr/lib64/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Xvfb': 'Xvfb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEasyProcessError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-00e87906d0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyvirtualdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyvirtualdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_display\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/uni/autonomous/autonomous_systems_project/.venv/lib64/python3.7/site-packages/pyvirtualdisplay/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, check_startup, randomizer, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'xvfb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         self._obj = self.display_class(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mcolor_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/uni/autonomous/autonomous_systems_project/.venv/lib64/python3.7/site-packages/pyvirtualdisplay/display.py\u001b[0m in \u001b[0;36mdisplay_class\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# TODO: check only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_installed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/uni/autonomous/autonomous_systems_project/.venv/lib64/python3.7/site-packages/pyvirtualdisplay/xvfb.py\u001b[0m in \u001b[0;36mcheck_installed\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_stdout_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_stderr_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/uni/autonomous/autonomous_systems_project/.venv/lib64/python3.7/site-packages/easyprocess/__init__.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/uni/autonomous/autonomous_systems_project/.venv/lib64/python3.7/site-packages/easyprocess/__init__.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OSError exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moserror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moserror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moserror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEasyProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process was started (pid=%s)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEasyProcessError\u001b[0m: start error <EasyProcess cmd_param=['Xvfb', '-help'] cmd=['Xvfb', '-help'] oserror=[Errno 2] No such file or directory: 'Xvfb': 'Xvfb' return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
     ]
    }
   ],
   "source": [
    "# This installs a \n",
    "!apt-get install -y xvfb x11-utils\n",
    "\n",
    "!pip install pyvirtualdisplay==0.2.* \\\n",
    "             PyOpenGL==3.1.* \\\n",
    "             PyOpenGL-accelerate==3.1.*\n",
    "\n",
    "# This starts the display\n",
    "import pyvirtualdisplay\n",
    "\n",
    "_display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
    "_ = _display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cedZKEAZDast"
   },
   "outputs": [],
   "source": [
    "from gym.wrappers.frame_stack import FrameStack\n",
    "from gym.wrappers.gray_scale_observation import GrayScaleObservation\n",
    "from collections import namedtuple\n",
    "import gym\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFeNLFFuDims"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "frames = 4\n",
    "env_name = 'Breakout-v0'\n",
    "env = FrameStack(GrayScaleObservation(gym.make(env_name)), frames)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ju6R5xsI3ta"
   },
   "source": [
    "# Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoyJzxuwI7Bg"
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'reward', 'next_state'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cX470chbIr7o"
   },
   "source": [
    "# DQN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmuSz5GhEhMZ"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, h, w, outputs, frame_stack=4, rgb=False):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        Construct a new DQN object.\n",
    "        \n",
    "        :param h: The height of the image.\n",
    "        :param w: The width of the image.\n",
    "        :param outputs: The number of outputs.\n",
    "        \"\"\"\n",
    "\n",
    "        if rgb:\n",
    "          color_channels = 3\n",
    "        else:\n",
    "          color_channels = 1\n",
    "        \n",
    "        self.input_channels = color_channels * frame_stack\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.input_channels, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # (Size - Kernel size + 2 * Padding) // Stride --> see https://cs231n.github.io/convolutional-networks/\n",
    "        def conv2d_size_out(size, kernel=5, stride=2):\n",
    "            return (size - kernel) // stride + 1\n",
    "        \n",
    "        # Compute convolution output dimensions\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        \n",
    "        # Conv output width * conv output height * conv output channels\n",
    "        self.linear_input_size = convw * convh * 32\n",
    "                 \n",
    "        # A fully connected layer for the output\n",
    "        self.head = nn.Linear(self.linear_input_size, outputs)\n",
    "        \n",
    "    # NN forward pass    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x))) # TODO should we use maxpooling? or any other pooling?\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dajfV_DTJdKV"
   },
   "outputs": [],
   "source": [
    "class DQNTraining():\n",
    "\n",
    "  def __init__(self, env, batch_size=128, gamma=0.999, \n",
    "                 eps_start=0.9, eps_end=0.05, eps_decay=200, \n",
    "                 update_every=10, memory_size=10000):\n",
    "    \"\"\"\n",
    "    The training support object has two DQNs: policy and target, see \n",
    "    https://greentec.github.io/reinforcement-learning-third-en/#soft-update-target-network\n",
    "\n",
    "    :param env: gym environment\n",
    "    :param batch_size: how many transitions are sampled from the replay memory for training.\n",
    "    :param gamma: discount.\n",
    "    :param eps_start: initial exploration rate (for epsilon-greedy policy).\n",
    "    :param eps_decay: controls the rate of decay (for epsilon-greedy policy).\n",
    "    :param eps_end: final exploration rate (for epsilon-greedy policy).\n",
    "    :param update_every: how often the target net is updated with weights from the policy network.\n",
    "    :param memory_size: replay buffer size\n",
    "    \"\"\"\n",
    "\n",
    "    self.env = env\n",
    "    self.batch_size = batch_size\n",
    "    self.gamma = gamma\n",
    "    self.eps_start = eps_start\n",
    "    self.eps_end = eps_end\n",
    "    self.eps_decay = eps_decay\n",
    "    self.update_every = update_every\n",
    "\n",
    "    # Might be useful later on\n",
    "    self.n_actions = env.action_space.n\n",
    "\n",
    "    # State dimensions\n",
    "    self.state_h = env.observation_space.shape[1]\n",
    "    self.state_w = env.observation_space.shape[2]\n",
    "    print(self.state_w)\n",
    "\n",
    "    # Policy & target nets\n",
    "    self.policy_network = DQN(self.state_h, self.state_w, self.n_actions, rgb=False).to(device)\n",
    "    self.target_network = DQN(self.state_h, self.state_w, self.n_actions, rgb=False).to(device)\n",
    "    self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "    self.target_network.eval()\n",
    "\n",
    "    # Optimizer\n",
    "    self.optimizer = optim.RMSprop(self.policy_network.parameters())\n",
    "\n",
    "    # Replay memory\n",
    "    self.memory = ReplayMemory(memory_size)\n",
    "\n",
    "    self.total_steps = 0\n",
    "\n",
    "  def select_action(self, state):\n",
    "    sample = random.random()\n",
    "    eps_threshold = self.eps_end + (self.eps_start - self.eps_end) * \\\n",
    "                    math.exp(-1. * self.total_steps / self.eps_decay)\n",
    "    self.total_steps += 1\n",
    "    \n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return self.policy_network(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(self.n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "  def optimize_model(self):\n",
    "\n",
    "    if len(self.memory) < self.batch_size:\n",
    "        return\n",
    "    \n",
    "    # Optimization steps sample the replay buffer\n",
    "    transitions = self.memory.sample(self.batch_size)\n",
    "    \n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Convert arrays to tensors\n",
    "    state_batch = torch.cat(batch.state).view(self.batch_size, 12, self.state_h, self.state_w).float()\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.tensor(batch.reward, device=device)\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = [s for s in batch.next_state if s is not None]\n",
    "    non_final_len = torch.sum(non_final_mask.long())\n",
    "    non_final_next_states = torch.cat(non_final_next_states).view(non_final_len, 12, self.state_h, self.state_w).float()\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = self.policy_network(state_batch).gather(1, action_batch)[non_final_mask]\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(self.batch_size, device=device)\n",
    "    next_state_values = self.target_network(non_final_next_states).max(1)[0].detach()\n",
    "    \n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * self.gamma) + reward_batch[non_final_mask]\n",
    "    \n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    # Optimize the model\n",
    "    self.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in self.policy_network.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    self.optimizer.step()\n",
    "\n",
    "  def training_loop(self, num_episodes, render=False):\n",
    "    if render:\n",
    "      _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "      print('Episode: %d/%d' % (episode+1, num_episodes))\n",
    "      # Reset env\n",
    "      state = torch.tensor(env.reset(), device=device)\n",
    "      done = False\n",
    "      if render:\n",
    "        img = ax.imshow(env.render(mode='rgb_array'))      \n",
    "      while not done:\n",
    "\n",
    "        if render:\n",
    "          img.set_data(env.render(mode='rgb_array')) \n",
    "          ax.axis('off')\n",
    "          display.display(plt.gcf())\n",
    "          display.clear_output(wait=True)\n",
    "        \n",
    "        # Let agent perform an action according to an eps-greedy policy\n",
    "        action = self.select_action(state.view((1, 12, self.state_h, self.state_w)).float()) # TODO avoid explicit reference to frame stack\n",
    "        \n",
    "        # Take step\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "        # Convert to tensors\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        if not done:\n",
    "          next_state = torch.tensor(torch.from_numpy(np.array(next_state)), device=device)\n",
    "        else:\n",
    "          next_state = None\n",
    "        \n",
    "        # Remember transition\n",
    "        self.memory.push(state, action, reward, next_state)\n",
    "\n",
    "        # Run optimization step\n",
    "        self.optimize_model()\n",
    "\n",
    "        # Update state \n",
    "        if not done:\n",
    "          state = torch.tensor(next_state, device=device)\n",
    "        \n",
    "      if episode % self.update_every == 0:\n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1nG8TutLRIo"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 12, 210, 160]' is invalid for input of size 134400",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-94894c1d2a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-b640d7749341>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(self, num_episodes, render)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Let agent perform an action according to an eps-greedy policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO avoid explicit reference to frame stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Take step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 12, 210, 160]' is invalid for input of size 134400"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = DQNTraining(env)\n",
    "agent.training_loop(100, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpmUg02wUtks"
   },
   "outputs": [],
   "source": [
    "# TODO checkpointing\n",
    "torch.save({\n",
    "            'model_state_dict': agent.policy_network.state_dict(),\n",
    "            'optimizer_state_dict': agent.optimizer.state_dict(),\n",
    "            }, 'policy.pkl')\n",
    "\n",
    "torch.save({\n",
    "            'model_state_dict': agent.target_network.state_dict(),\n",
    "            }, 'target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WNj86NaOWQUA"
   },
   "outputs": [],
   "source": [
    "old_agent = DQNTraining(env, eps_start=0.05)\n",
    "policy_checkpoint = torch.load('policy.pkl')\n",
    "target_checkpoint = torch.load('target.pkl')\n",
    "old_agent.policy_network.load_state_dict(policy_checkpoint['model_state_dict'])\n",
    "old_agent.target_network.load_state_dict(target_checkpoint['model_state_dict'])\n",
    "old_agent.optimizer.load_state_dict(policy_checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "ADm8cc0ZXRiA",
    "outputId": "a6a439c7-c743-482a-e404-a0c07bb4f723"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "old_agent.training_loop(1, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [142, 142, 142,  ..., 122,  48, 180],\n",
       "         [122,  48, 180,  ...,  48, 180, 122],\n",
       "         [ 48, 180, 122,  ..., 142, 142, 142]],\n",
       "\n",
       "        [[142, 142, 142,  ..., 122,  48, 180],\n",
       "         [122,  48, 180,  ...,  48, 180, 122],\n",
       "         [ 48, 180, 122,  ..., 142, 142, 142],\n",
       "         ...,\n",
       "         [142, 142, 142,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ..., 142, 142, 142]],\n",
       "\n",
       "        [[142, 142, 142,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ..., 142, 142, 142],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [142, 142, 142,  ..., 122,  48, 180],\n",
       "         [122,  48, 180,  ...,  48, 180, 122],\n",
       "         [ 48, 180, 122,  ..., 142, 142, 142]],\n",
       "\n",
       "        [[142, 142, 142,  ..., 122,  48, 180],\n",
       "         [122,  48, 180,  ...,  48, 180, 122],\n",
       "         [ 48, 180, 122,  ..., 142, 142, 142],\n",
       "         ...,\n",
       "         [142, 142, 142,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ..., 142, 142, 142]],\n",
       "\n",
       "        [[142, 142, 142,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ..., 142, 142, 142],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "torch.from_numpy(np.array(env.step(env.action_space.sample())[0])).view((12, 210, 160))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMqnCT/lIHPuaY8BTKUQJaN",
   "include_colab_link": true,
   "name": "Pytorch DQN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
